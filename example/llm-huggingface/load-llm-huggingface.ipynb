{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [Malaya/example/llm-huggingface](https://github.com/huseinzol05/Malaya/tree/master/example/llm-huggingface).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "This notebook is running using GPU.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Results generated using stochastic methods.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 15:40:06.320150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-12 15:40:06.413586: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-12 15:40:07.140147: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-12 15:40:07.140197: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-12 15:40:07.140201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/husein/.local/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.4.0 and strictly below 2.7.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/husein/.local/lib/python3.8/site-packages/tensorflow_addons/utils/resource_loader.py:78: UserWarning: You are currently using TensorFlow 2.11.0 and trying to load a custom op (custom_ops/seq2seq/_beam_search_ops.so).\n",
      "TensorFlow Addons has compiled its custom ops against TensorFlow 2.6.0, and there are no compatibility guarantees between the two versions. \n",
      "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
      " If you do, do not file an issue on Github. This is a known limitation.\n",
      "\n",
      "It might help you to fallback to pure Python ops by setting environment variable `TF_ADDONS_PY_OPS=1` or using `tfa.options.disable_custom_kernel()` in your code. To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
      "\n",
      "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.6.0 and strictly below 2.7.0.\n",
      " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
      "\n",
      "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "WARNING:malaya_boilerplate.frozen_graph:Cannot import beam_search_ops from Tensorflow Addons, ['malaya.jawi_rumi.deep_model', 'malaya.phoneme.deep_model', 'malaya.rumi_jawi.deep_model', 'malaya.stem.deep_model'] will not available to use, make sure Tensorflow Addons version >= 0.12.0\n",
      "WARNING:malaya_boilerplate.frozen_graph:check compatible Tensorflow version with Tensorflow Addons at https://github.com/tensorflow/addons/releases\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp5ll517yf\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp5ll517yf/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import malaya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available HuggingFace models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base model</th>\n",
       "      <th>Size (GB)</th>\n",
       "      <th>context length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mesolitica/llama-7b-hf-1024-ms-qlora</th>\n",
       "      <td>https://huggingface.co/meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>13.85</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/llama-7b-hf-1536-ms-qlora</th>\n",
       "      <td>https://huggingface.co/meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>13.85</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           base model  \\\n",
       "mesolitica/llama-7b-hf-1024-ms-qlora  https://huggingface.co/meta-llama/Llama-2-7b-hf   \n",
       "mesolitica/llama-7b-hf-1536-ms-qlora  https://huggingface.co/meta-llama/Llama-2-7b-hf   \n",
       "\n",
       "                                     Size (GB) context length  \n",
       "mesolitica/llama-7b-hf-1024-ms-qlora     13.85           1024  \n",
       "mesolitica/llama-7b-hf-1536-ms-qlora     13.85           1536  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya.llm.available_huggingface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HuggingFace model\n",
    "\n",
    "```python\n",
    "def huggingface(\n",
    "    model: str = 'mesolitica/llama-7b-hf-1024-ms-qlora',\n",
    "    force_check: bool = True,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load LLM HuggingFace model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: str, optional (default='mesolitica/llama-7b-hf-1024-ms-qlora')\n",
    "        Check available models at `malaya.llm.available_huggingface()`.\n",
    "    force_check: bool, optional (default=True)\n",
    "        Force check model one of malaya model.\n",
    "        Set to False if you have your own huggingface model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: malaya.torch_model.huggingface.LLM\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:malaya.torch_model.llm:compute capability is >= 8, able to use bloat16.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8593eea1942462c92e419eb6e72e852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = malaya.llm.huggingface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate\n",
    "\n",
    "```python\n",
    "def generate(\n",
    "    self,\n",
    "    query: str,\n",
    "    split_by='\\n#Bot:',\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate respond from user input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query: str\n",
    "        User input.\n",
    "\n",
    "    **kwargs: vector arguments pass to huggingface `generate` method.\n",
    "        Read more at https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "\n",
    "        If you are using `use_ctranslate2`, vector arguments pass to ctranslate2 `translate_batch` method.\n",
    "        Read more at https://opennmt.net/CTranslate2/python/ctranslate2.Translator.html?highlight=translate_batch#ctranslate2.Translator.translate_batch\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: str\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Perdana Menteri Malaysia pada masa ini ialah Datuk Seri Ismail Sabri Yaakob.\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(\n",
    "    'siapa perdana menteri malaysia',\n",
    "    max_new_tokens = 300,\n",
    "    temperature = 1.0,\n",
    "    top_p = 0.95,\n",
    "    top_k = 50,\n",
    "    num_beams = 1,\n",
    "    do_sample = True,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Tampatkan projek Hello-World dalam direktori yang sesuai dalam komputer anda.\n",
      "2. Jalankan arahan PHP \"composer init\" untuk mencipta konfigurasi ciptaan baru untuk projek anda.\n",
      "3. Jalankan arahan PHP \"composer require --dev phalcon/diagnostics\" untuk memuat turun aplikasi baharu Phalcon dan membuat kod untuk diagnostikkan.\n",
      "4. Jalankan arahan PHP \"composer generate-class\" untuk mencipta kelas baru untuk projek anda.\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(\n",
    "    'macam mana nak mulakan project hello-world menggunakan php',\n",
    "    max_new_tokens = 1000,\n",
    "    temperature = 1.0,\n",
    "    top_p = 0.95,\n",
    "    top_k = 50,\n",
    "    num_beams = 1,\n",
    "    do_sample = True,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Cipta projek Android dalam Android Studio.\n",
      "2. Impor baris arahan berikut ke dalam projek:\n",
      "\n",
      "```\n",
      "import androidx.appcompat.app.AppCompatActivity\n",
      "import android.os.Bundle\n",
      "import android.view.View\n",
      "import kotlinx.android.synthetic.main.activity_main.*\n",
      "```\n",
      "3. Di dalam fail MainActivity.kt, tambahkan baris-baris berikut:\n",
      "\n",
      "```\n",
      "override fun onCreate(savedInstanceState: Bundle?) {\n",
      "    super.onCreate(savedInstanceState)\n",
      "    setContentView(R.layout.activity_main)\n",
      "}\n",
      "```\n",
      "4. Di dalam ActivityMain.kt, tambahkan baris-baris berikut:\n",
      "\n",
      "```\n",
      "class MainActivity : AppCompatActivity() {\n",
      "    override fun onCreate(savedInstanceState: Bundle?) {\n",
      "        super.onCreate(savedInstanceState)\n",
      "        setContentView(R.layout.activity_main)\n",
      "\n",
      "        btn_hello_kotlin.setOnClickListener {\n",
      "            Toast.makeText(this, \"Hello Kotlin!\", Toast.LENGTH_SHORT).show()\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "5. Buka projek Android Studio dan langganan fail ke dalam ciptaan Android Studio yang baharu.\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(\n",
    "    'bina simple kotlin app berserta code',\n",
    "    max_new_tokens = 1000,\n",
    "    temperature = 1.0,\n",
    "    top_p = 0.95,\n",
    "    top_k = 50,\n",
    "    num_beams = 1,\n",
    "    do_sample = True,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd \n",
      "import numpy as np \n",
      "from sklearn.model_selection import train_test_split \n",
      "from sklearn.linear_model import LogisticRegression \n",
      "\n",
      "# read in the data \n",
      "data = pd.read_csv(\"data.csv\") \n",
      "\n",
      "# split the data into training and testing sets \n",
      "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.2) \n",
      "\n",
      "# fit the model \n",
      "model = LogisticRegression(random_state=42) \n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# evaluate the model \n",
      "score = model.score(X_test, y_test) \n",
      "print(\"The model's accuracy is {}\".format(score))\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(\n",
    "    'contoh python code to predict harga rumah',\n",
    "    max_new_tokens = 1000,\n",
    "    temperature = 1.0,\n",
    "    top_p = 0.95,\n",
    "    top_k = 50,\n",
    "    num_beams = 1,\n",
    "    do_sample = True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "```python\n",
    "def generate_stream(\n",
    "    self,\n",
    "    query: str,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate respond from user input in streaming mode.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query: str\n",
    "        User input.\n",
    "    **kwargs: vector arguments pass to huggingface `generate` method.\n",
    "        Read more at https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: str\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "from \n",
      "\n",
      "from \n",
      "\n",
      "from \n",
      "\n",
      "from \n",
      "\n",
      "from \n",
      "\n",
      "from \n",
      "\n",
      "from sklearn.linear_model \n",
      "\n",
      "from sklearn.linear_model import \n",
      "\n",
      "from sklearn.linear_model import \n",
      "\n",
      "from sklearn.linear_model import \n",
      "\n",
      "from sklearn.linear_model import \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set, \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr.fit(training_set['price'], \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = \n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "\n",
      "# Load training dataset\n",
      "training_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle/sample_dataset/master/train.csv\")\n",
      "\n",
      "# Split into training and testing sets\n",
      "training_set, testing_set = train_test_split(training_df['price'], training_df['category'], test_size=0.25)\n",
      "\n",
      "# Train Logistic Regression Model\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "lr.fit(training_set['price'], training_set['category'])\n",
      "\n",
      "# Make predictions\n",
      "predictions = lr.predict(testing_set['price'])\r"
     ]
    }
   ],
   "source": [
    "for s in model.generate_stream(\n",
    "    'contoh python code to predict harga rumah',\n",
    "    max_new_tokens = 1000,\n",
    "    temperature = 1.0,\n",
    "    top_p = 0.95,\n",
    "    top_k = 50,\n",
    "    num_beams = 1,\n",
    "    do_sample = True,\n",
    "):\n",
    "    \n",
    "    print(s, end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run in CLI, it will properly flush the output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
