{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isi Penting Generator product description style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a long text with product description style given isi penting (important facts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [Malaya/example/isi-penting-generator-product-description-style](https://github.com/huseinzol05/Malaya/tree/master/example/isi-penting-generator-product-description-style).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Results generated using stochastic methods.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.76 s, sys: 3.98 s, total: 6.74 s\n",
      "Wall time: 2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import malaya\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mesolitica/finetune-isi-penting-generator-t5-small-standard-bahasa-cased': {'Size (MB)': 242,\n",
       "  'ROUGE-1': 0.24620333,\n",
       "  'ROUGE-2': 0.05896076,\n",
       "  'ROUGE-L': 0.15158954,\n",
       "  'Suggested length': 1024},\n",
       " 'mesolitica/finetune-isi-penting-generator-t5-base-standard-bahasa-cased': {'Size (MB)': 892,\n",
       "  'ROUGE-1': 0.24620333,\n",
       "  'ROUGE-2': 0.05896076,\n",
       "  'ROUGE-L': 0.15158954,\n",
       "  'Suggested length': 1024}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya.generator.isi_penting.available_huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HuggingFace\n",
    "\n",
    "Transformer Generator in Malaya is quite unique, most of the text generative model we found on the internet like GPT2 or Markov, simply just continue prefix input from user, but not for Transformer Generator. We want to generate an article or karangan like high school when the users give 'isi penting'.\n",
    "\n",
    "```python\n",
    "def huggingface(\n",
    "    model: str = 'mesolitica/finetune-isi-penting-generator-t5-base-standard-bahasa-cased',\n",
    "    force_check: bool = True,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load HuggingFace model to generate text based on isi penting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: str, optional (default='mesolitica/finetune-isi-penting-generator-t5-base-standard-bahasa-cased')\n",
    "        Check available models at `malaya.generator.isi_penting.available_huggingface`.\n",
    "    force_check: bool, optional (default=True)\n",
    "        Force check model one of malaya model.\n",
    "        Set to False if you have your own huggingface model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: malaya.torch_model.huggingface.IsiPentingGenerator\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model = malaya.generator.isi_penting.huggingface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate\n",
    "\n",
    "```python\n",
    "def generate(\n",
    "    self,\n",
    "    strings: List[str],\n",
    "    mode: str = 'surat-khabar',\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    generate a long text given a isi penting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    strings : List[str]\n",
    "    mode: str, optional (default='surat-khabar')\n",
    "        Mode supported. Allowed values:\n",
    "\n",
    "        * ``'surat-khabar'`` - news style writing.\n",
    "        * ``'tajuk-surat-khabar'`` - headline news style writing.\n",
    "        * ``'artikel'`` - article style writing.\n",
    "        * ``'penerangan-produk'`` - product description style writing.\n",
    "        * ``'karangan'`` - karangan sekolah style writing.\n",
    "\n",
    "    **kwargs: vector arguments pass to huggingface `generate` method.\n",
    "        Read more at https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: List[str]\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good thing about HuggingFace\n",
    "\n",
    "In `generate` method, you can do greedy, beam, sampling, nucleus decoder and so much more, read it at https://huggingface.co/blog/how-to-generate\n",
    "\n",
    "And recently, huggingface released https://huggingface.co/blog/introducing-csearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "isi_penting = ['ayam yang sihat dan sejahtera', 'nasi ayam yang sedap dan lazat', 'kedai bernama Husein Nasi Ayam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaces_between_special_tokens is deprecated and will be removed in transformers v5. It was adding spaces between `added_tokens`, not special tokens, and does not exist in our fast implementation. Future tokenizers will handle the decoding process on a per-model rule.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Makanan yang enak dan sihat untuk anjing yang sihat dan sejahtera. Tidak ada '\n",
      " 'jagung, soya, jagung, pemanis dan gluten yang ditambahkan. Tidak ada '\n",
      " 'pengawet yang ditambahkan. Husein Nasi Ayam adalah makanan yang sihat dan '\n",
      " 'lazat yang dibuat dengan ayam dan ayam yang sihat dan lazat. Biarkan haiwan '\n",
      " 'kesayangan anda makan dan sihat dengan ayam yang sedap dan lazat. Apabila '\n",
      " 'anda menghidangkannya, Husein memberitahu kami bahawa dia akan membawa anda '\n",
      " 'ke kedai bernama Husein Nasi Ayam. Kami meletakkan resipi kami yang '\n",
      " 'berkualiti tinggi di dalam kotak, jadi ada sesuatu yang anda boleh '\n",
      " 'bergantung pada Husein untuk makanan hebat ini. Dengan 50 ons, anda boleh '\n",
      " 'memberi makan Husein kepada anjing kegemaran anda. Mengenai Husein Kami '\n",
      " 'menggunakan bahan-bahan yang berkualiti, termasuk 100% Nasi Ayam Amerika, '\n",
      " '100% Gula Dan Dicairkan. Kami tidak pernah menambahkan bahan kimia, hormon '\n",
      " 'atau antibiotik ke dalam rasa buatan, atau buatan. Proses kami telah diuji '\n",
      " 'untuk memastikan ia adalah makanan yang lazat, semula jadi, dan sihat untuk '\n",
      " 'anjing. Kami hanya menggunakan bahan-bahan berkualiti tinggi dan kami '\n",
      " 'menggunakan 100% bahan-bahan tersebut']\n"
     ]
    }
   ],
   "source": [
    "pprint(model.generate(isi_penting, mode = 'penerangan-produk',\n",
    "    do_sample=True, \n",
    "    max_length=256, \n",
    "    top_k=50, \n",
    "    top_p=0.95,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Husein Nasi Ayam adalah makanan yang enak dan lazat yang dibuat dengan ayam '\n",
      " 'yang sihat dan sejahtera. Dibungkus dengan nasi yang enak dan sedap di dalam '\n",
      " 'beg plastik, Husein Nasi Ayam sangat sesuai sebagai makanan ringan atau '\n",
      " 'makanan ringan. Ia adalah makanan ringan yang enak, lazat dan lazat yang '\n",
      " 'dibuat dengan ayam yang sihat dan sejahtera.']\n"
     ]
    }
   ],
   "source": [
    "pprint(model.generate(isi_penting, mode = 'penerangan-produk',\n",
    "    do_sample=True, \n",
    "    max_length=256, \n",
    "    penalty_alpha=0.8, top_k=4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "isi_penting = ['sabun lembut untuk kulit anda', \n",
    "               'sabun bebas dari DNA babi',\n",
    "               '44 herba dipetik oleh ibu tunggal yang cantik lagi ayu',\n",
    "               'sabun bebas dari kes rasuah SPRM',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tidak ada sabun lembut untuk kulit anda. Sebenarnya, sabun bebas dari DNA '\n",
      " 'babi. 44 herba dipetik oleh ibu tunggal yang cantik lagi ayu. Oleh itu, '\n",
      " 'sabun bebas dari kes rasuah SPRM ini telah memberi makan kepada kulit anda, '\n",
      " 'anda juga tahu bahawa anda benar-benar ingin menjauhkannya daripada '\n",
      " 'tercekik. Ini bukan sabun yang penuh dengan wangi. Diambil dari daging '\n",
      " 'lembu, itik dan tembikai dari kacang, kacang hijau dan kentang, sabun semula '\n",
      " 'jadi ini memberikan kulit anda aroma segar dan pedas. Formula emolien semula '\n",
      " 'jadi dicampur dengan vitamin C dan vitamin E dan dicampurkan dengan aloe '\n",
      " 'vera. Dibuat dengan bahan semula jadi, sabun ini mempunyai sifat '\n",
      " 'anti-penuaan, antiseptik dan anti-oksidan. Bahan-bahan semula jadi dan '\n",
      " 'emolien semula jadi terdapat dalam bentuk cecair dan susu yang menenangkan.']\n"
     ]
    }
   ],
   "source": [
    "pprint(model.generate(isi_penting, do_sample=True, mode = 'penerangan-produk',\n",
    "    max_length=256,\n",
    "    top_k=50, \n",
    "    top_p=0.95, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['- Bahan semula jadi dan semula jadi. - Bebas dari polimer, alkohol, dan '\n",
      " 'bahan kimia yang keras. - Bebas dari DNA babi. - Bebas sulfat, phthalates, '\n",
      " 'sulfat, dan bahan kimia keras yang keras. - Bebas daripada bahan kimia yang '\n",
      " 'keras. - Bebas daripada bahan kimia yang keras. - Bebas dari alkohol, '\n",
      " 'alkohol, dan bahan kimia keras yang keras. - Bebas dari polimer, alkohol, '\n",
      " 'dan bahan kimia keras yang keras. - Bebas dari polimer, alkohol, dan bahan '\n",
      " 'kimia keras yang keras. - Bebas dari alkohol, alkohol, dan bahan kimia '\n",
      " 'keras. - Bebas dari alkohol, alkohol, dan bahan kimia keras. - Bebas dari '\n",
      " 'alkohol, alkohol, dan bahan kimia keras. - Bebas daripada alkohol alkohol, '\n",
      " 'alkohol, dan bahan kimia keras. - Bebas dari alkohol alkohol, alkohol, dan '\n",
      " 'bahan kimia keras. - Bebas alkohol alkohol']\n"
     ]
    }
   ],
   "source": [
    "pprint(model.generate(isi_penting, mode = 'penerangan-produk',\n",
    "    do_sample=True, \n",
    "    max_length=256, \n",
    "    penalty_alpha=0.8, top_k=4,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you give better isi penting, the results will be much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ms.wikipedia.org/wiki/Burger_Ramly\n",
    "isi_penting = ['Penubuhan Makma Mikrobiologi',\n",
    "               'mengawal kualiti produk',\n",
    "               'memastikan produknya adalah suci',\n",
    "               'satu tempat penyelidikan dan pembangunan produk',\n",
    "              'peralatan teknologi tinggi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Penubuhan Makma Mikrobiologi: Produk \"Penubuhan Makma Mikrobiologi\" direka '\n",
      " 'untuk mengawal kualiti produk sambil memastikan produknya suci. \"Penubuhan '\n",
      " 'Makma Mikrobiologi\" adalah alat yang direkayasa khas dan generik yang telah '\n",
      " \"dikembangkan dan dikembangkan paperback 'Tunnel Project' sejak tahun 2005. \"\n",
      " '\"Penubuhan Makma Mikrobiologi\" adalah salah satu cara untuk mendapatkan '\n",
      " 'peralatan teknologi tinggi dengan cekap. Sebagai satu tempat penyelidikan '\n",
      " 'dan pembangunan produk, \"Penubuhan Makma Mikrobiologi\" adalah asas yang '\n",
      " 'sangat diperlukan dalam membina produk ini dan seterusnya.']\n"
     ]
    }
   ],
   "source": [
    "pprint(model.generate(isi_penting, do_sample=True, mode = 'penerangan-produk',\n",
    "    max_length=256,\n",
    "    top_k=50, \n",
    "    top_p=0.95, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Penubuhan Makma Mikrobiologi adalah alat untuk mengawal kualiti produk yang '\n",
      " 'dihasilkan oleh organisma hidup dan peralatan teknologi tinggi. Ia mempunyai '\n",
      " 'banyak kegunaan dalam penyelidikan biologi, perubatan, kejuruteraan dan '\n",
      " 'industri. Produk ini adalah alat yang digunakan dalam industri perubatan dan '\n",
      " 'farmaseutikal dan telah menjadi salah satu alat yang paling dihormati di '\n",
      " 'dunia untuk penyelidikan dan pembangunan. Alat ini adalah alat penting untuk '\n",
      " 'memastikan produknya suci. Penubuhan Makma Mikrobiologi adalah alat yang '\n",
      " 'digunakan dalam industri perubatan dan farmaseutikal dan telah menjadi salah '\n",
      " 'satu alat yang paling dihormati di dunia untuk penyelidikan dan pembangunan. '\n",
      " 'Alat ini adalah alat penting untuk memastikan produknya suci. Penubuhan '\n",
      " 'Makma Mikrobiologi adalah alat penting untuk memastikan produknya adalah '\n",
      " 'suci. Penubuhan Makma Mikrobiologi adalah alat penting untuk memastikan '\n",
      " 'produknya suci. Penubuhan Makma Mikrobiologi adalah alat penting untuk '\n",
      " 'memastikan produknya adalah suci. Penubuhan Makma Mikrobiologi adalah alat '\n",
      " 'penting untuk memastikan produknya adalah suci.']\n"
     ]
    }
   ],
   "source": [
    "pprint(model.generate(isi_penting, mode = 'penerangan-produk',\n",
    "    do_sample=True, \n",
    "    max_length=256, \n",
    "    penalty_alpha=0.8, top_k=4,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
