{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --pre --force-reinstall mlc-ai-nightly-cu118 mlc-chat-nightly-cu118 -f https://mlc.ai/wheels\n",
    "# !pip3 install git+https://github.com/mlc-ai/mlc-llm/tree/main/mlc_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 18:36:27.379571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-12 18:36:27.530038: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-12 18:36:28.309853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-12 18:36:28.309910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-12 18:36:28.309913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/husein/.local/lib/python3.8/site-packages/tensorflow_probability/python/internal/backend/numpy/numpy_array.py:281: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  def _sequence_mask(lengths, maxlen=None, dtype=np.bool, name=None):  # pylint: disable=unused-argument\n"
     ]
    }
   ],
   "source": [
    "from mlc_llm import core as mlc_llm_core\n",
    "from malaya_boilerplate.utils import get_cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] <<SYS>>\\nawak chatbot yang baik\\n<</SYS>>\\n\\nhelo1     [/INST] helo2 </s><s>[INST] helo3 [/INST] helo4 </s><s>[INST] siapa [/INST]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = 'awak chatbot yang baik'\n",
    "texts = [f'<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n']\n",
    "chat_history = [('helo1    ', 'helo2'), ('helo3', 'helo4')]\n",
    "message = 'siapa'\n",
    "do_strip = False\n",
    "for user_input, response in chat_history:\n",
    "    user_input = user_input.strip() if do_strip else user_input\n",
    "    do_strip = True\n",
    "    texts.append(f'{user_input} [/INST] {response.strip()} </s><s>[INST] ')\n",
    "message = message.strip() if do_strip else message\n",
    "texts.append(f'{message} [/INST]')\n",
    "''.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>[INST] <<SYS>>\\nawak chatbot yang baik\\n<</SYS>>\\n\\n',\n",
       " 'helo1     [/INST] helo2 </s><s>[INST] ',\n",
       " 'helo3 [/INST] helo4 </s><s>[INST] ',\n",
       " 'siapa [/INST]']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('mesolitica/llama-7b-hf-1024-ms-qlora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁[',\n",
       " 'INST',\n",
       " ']',\n",
       " '▁<<',\n",
       " 'SY',\n",
       " 'S',\n",
       " '>>',\n",
       " '<0x0A>',\n",
       " 'y',\n",
       " 'ahu',\n",
       " '<0x0A>',\n",
       " '<',\n",
       " '</',\n",
       " 'SY',\n",
       " 'S',\n",
       " '>>',\n",
       " '<0x0A>',\n",
       " '<0x0A>',\n",
       " 'a',\n",
       " '▁[',\n",
       " '/',\n",
       " 'INST',\n",
       " ']',\n",
       " '▁b',\n",
       " '▁',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '▁[',\n",
       " 'INST',\n",
       " ']',\n",
       " '▁c',\n",
       " '▁[',\n",
       " '/',\n",
       " 'INST',\n",
       " ']',\n",
       " '▁d',\n",
       " '▁',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '▁[',\n",
       " 'INST',\n",
       " ']',\n",
       " '▁sia',\n",
       " 'pa',\n",
       " '▁[',\n",
       " '/',\n",
       " 'INST',\n",
       " ']']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(''.join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/husein/.cache/malaya/'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cache_dir('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_args = mlc_llm_core.convert_build_args_to_argparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights exist at /home/husein/.cache/malaya/models/llama-7b-hf-1024-ms-qlora, skipping download.\n",
      "Using path \"/home/husein/.cache/malaya/models/llama-7b-hf-1024-ms-qlora\" for model \"llama-7b-hf-1024-ms-qlora\"\n",
      "Target configured: cuda -keys=cuda,gpu -arch=sm_86 -max_num_threads=1024 -max_shared_memory_per_block=49152 -max_threads_per_block=1024 -registers_per_block=65536 -thread_warp_size=32\n"
     ]
    }
   ],
   "source": [
    "args = mlc_llm_core.BuildArgs(\n",
    "    hf_path = 'mesolitica/llama-7b-hf-1024-ms-qlora',\n",
    "    target = 'cuda',\n",
    "    artifact_path = get_cache_dir('')\n",
    ")\n",
    "parsed_args = mlc_llm_core._parse_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically using target for weight quantization: cuda -keys=cuda,gpu -arch=sm_86 -max_num_threads=1024 -max_shared_memory_per_block=49152 -max_threads_per_block=1024 -registers_per_block=65536 -thread_warp_size=32\n"
     ]
    },
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  7: TVMFuncCall\n  6: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::__mk_TVM22::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#1}>(tvm::__mk_TVM22::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#1}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::allocator<char>, tvm::runtime::TVMArgs const&)\n  5: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)\n  4: tvm::codegen::Build(tvm::IRModule, tvm::Target)\n  3: _ZN3tvm7runtime13PackedFun\n  2: tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const\n  1: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)\n  0: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<TVMFuncCreateFromCFunc::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#2}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) [clone .cold]\n  File \"tvm/_ffi/_cython/./packed_func.pxi\", line 56, in tvm._ffi._cy3.core.tvm_callback\n  File \"/home/husein/.local/lib/python3.8/site-packages/tvm/contrib/nvcc.py\", line 189, in tvm_callback_cuda_compile\n    ptx = compile_cuda(code, target_format=\"fatbin\")\n  File \"/home/husein/.local/lib/python3.8/site-packages/tvm/contrib/nvcc.py\", line 105, in compile_cuda\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n  File \"/usr/lib/python3.8/subprocess.py\", line 858, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/usr/lib/python3.8/subprocess.py\", line 1704, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'nvcc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_919873/2612810665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlc_llm_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model_from_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mlc-llm/mlc_llm/core.py\u001b[0m in \u001b[0;36mbuild_model_from_args\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mnew_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_category\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"minigpt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlc-llm/mlc_llm/utils.py\u001b[0m in \u001b[0;36mconvert_weights\u001b[0;34m(param_mgr, model_params, args)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mmod_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultGPUSchedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0mvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVirtualMachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start computing and quantizing weights... This may take a while.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tvm/relax/vm_build.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(mod, target, params, exec_mode, system_lib)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0mleftover_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vmcodegen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexec_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mtir_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_tir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftover_mod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_vmlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtir_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_libs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_lib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_lib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tvm/relax/vm_build.py\u001b[0m in \u001b[0;36m_vmlink\u001b[0;34m(builder, target, tir_mod, ext_libs, params, system_lib)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtir_mod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         lib = tvm.build(\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mtir_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_autodetect_system_lib_req\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_lib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tvm/driver/build_module.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(inputs, args, target, target_host, runtime, name, binds)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mannotated_mods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanon_target_map_and_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_mods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mrt_mod_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_driver_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtir_to_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_mods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mannotated_mods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanon_target_map_and_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_mods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi\u001b[0m in \u001b[0;36mtvm._ffi._cy3.core.PackedFuncBase.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi\u001b[0m in \u001b[0;36mtvm._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi\u001b[0m in \u001b[0;36mtvm._ffi._cy3.core.FuncCall3\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtvm/_ffi/_cython/./base.pxi\u001b[0m in \u001b[0;36mtvm._ffi._cy3.core.CHECK_CALL\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  7: TVMFuncCall\n  6: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::__mk_TVM22::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#1}>(tvm::__mk_TVM22::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#1}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::allocator<char>, tvm::runtime::TVMArgs const&)\n  5: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)\n  4: tvm::codegen::Build(tvm::IRModule, tvm::Target)\n  3: _ZN3tvm7runtime13PackedFun\n  2: tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const\n  1: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)\n  0: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<TVMFuncCreateFromCFunc::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#2}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) [clone .cold]\n  File \"tvm/_ffi/_cython/./packed_func.pxi\", line 56, in tvm._ffi._cy3.core.tvm_callback\n  File \"/home/husein/.local/lib/python3.8/site-packages/tvm/contrib/nvcc.py\", line 189, in tvm_callback_cuda_compile\n    ptx = compile_cuda(code, target_format=\"fatbin\")\n  File \"/home/husein/.local/lib/python3.8/site-packages/tvm/contrib/nvcc.py\", line 105, in compile_cuda\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n  File \"/usr/lib/python3.8/subprocess.py\", line 858, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/usr/lib/python3.8/subprocess.py\", line 1704, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'nvcc'"
     ]
    }
   ],
   "source": [
    "mlc_llm_core.build_model_from_args(parsed_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvcc: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
