{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/translated-MNLI/resolve/main/translated-mnli-train.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-MNLI/resolve/main/translated-mnli-dev_matched.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4898822981207315"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import json\n",
    "import random\n",
    "\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['contradiction', 'entailment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"annotator_labels\": [\"neutral\"], \"genre\": \"government\", \"gold_label\": \"neutral\", \"pairID\": \"31193n\", \"promptID\": \"31193\", \"sentence1\": \"Conceptually cream skimming has two basic dimensions - product and geography.\", \"sentence1_binary_parse\": \"( ( Conceptually ( cream skimming ) ) ( ( has ( ( ( two ( basic dimensions ) ) - ) ( ( product and ) geography ) ) ) . ) )\", \"sentence1_parse\": \"(ROOT (S (NP (JJ Conceptually) (NN cream) (NN skimming)) (VP (VBZ has) (NP (NP (CD two) (JJ basic) (NNS dimensions)) (: -) (NP (NN product) (CC and) (NN geography)))) (. .)))\", \"sentence2\": \"Product and geography are what make cream skimming work. \", \"sentence2_binary_parse\": \"( ( ( Product and ) geography ) ( ( are ( what ( make ( cream ( skimming work ) ) ) ) ) . ) )\", \"sentence2_parse\": \"(ROOT (S (NP (NN Product) (CC and) (NN geography)) (VP (VBP are) (SBAR (WHNP (WP what)) (S (VP (VBP make) (NP (NP (NN cream)) (VP (VBG skimming) (NP (NN work)))))))) (. .)))\", \"translate\": [\"Skim krim konseptual mempunyai dua dimensi asas - produk dan geografi.\", \"Produk dan geografi adalah apa yang membuat krim skimming berfungsi.\"]}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 translated-mnli-train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392702it [00:03, 106394.65it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('train.json', 'w') as fopen_jsonl:\n",
    "    with open('translated-mnli-train.jsonl') as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            data = json.loads(l)\n",
    "            label = data['gold_label']\n",
    "            if label not in labels:\n",
    "                continue\n",
    "            if label == '-':\n",
    "                continue\n",
    "            \n",
    "            label = labels.index(label)\n",
    "            sent1 = data['sentence1'].strip()\n",
    "            sent2 = data['sentence2'].strip()\n",
    "            \n",
    "            sent1_ms = data['translate'][0].strip()\n",
    "            sent2_ms = data['translate'][1].strip()\n",
    "            \n",
    "            left = f'ayat1: {sent1} ayat2: {sent2}'\n",
    "            d = {\"src\": left, \"label\": label}\n",
    "            fopen_jsonl.write(f'{json.dumps(d)}\\n')\n",
    "            \n",
    "            left = f'ayat1: {sent1} ayat2: {sent2_ms}'\n",
    "            d = {\"src\": left, \"label\": label}\n",
    "            fopen_jsonl.write(f'{json.dumps(d)}\\n')\n",
    "            \n",
    "            left = f'ayat1: {sent1_ms} ayat2: {sent2_ms}'\n",
    "            d = {\"src\": left, \"label\": label}\n",
    "            fopen_jsonl.write(f'{json.dumps(d)}\\n')\n",
    "            \n",
    "            left = f'ayat1: {sent1_ms} ayat2: {sent2}'\n",
    "            d = {\"src\": left, \"label\": label}\n",
    "            fopen_jsonl.write(f'{json.dumps(d)}\\n')\n",
    "    \n",
    "    with open('sentiment.json') as fopen:\n",
    "        data = json.load(fopen)\n",
    "        for i in range(len(data['X1'])):\n",
    "            l = data['X1'][i]\n",
    "            r = data['X2'][i]\n",
    "            left = f'ayat1: {l} ayat2: {r}'\n",
    "            d = {\"src\": left, \"label\": data['Y'][i]}\n",
    "            fopen_jsonl.write(f'{json.dumps(d)}\\n')\n",
    "            \n",
    "    with open('topics.json') as fopen:\n",
    "        data = json.load(fopen)\n",
    "        for i in range(len(data['X1'])):\n",
    "            l = data['X1'][i]\n",
    "            r = data['X2'][i]\n",
    "            left = f'ayat1: {l} ayat2: {r}'\n",
    "            d = {\"src\": left, \"label\": data['Y'][i]}\n",
    "            fopen_jsonl.write(f'{json.dumps(d)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shuf train.json > shuffled-train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:00, 92967.31it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('test.json', 'w') as fopen_jsonl:\n",
    "    with open('translated-mnli-dev_matched.jsonl') as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            data = json.loads(l)\n",
    "            label = data['gold_label']\n",
    "            if label not in labels:\n",
    "                continue\n",
    "            if label == '-':\n",
    "                continue\n",
    "            \n",
    "            label = labels.index(label)\n",
    "                \n",
    "            sent1 = data['sentence1'].strip()\n",
    "            sent2 = data['sentence2'].strip()\n",
    "            \n",
    "            sent1_ms = data['translate'][0].strip()\n",
    "            sent2_ms = data['translate'][1].strip()\n",
    "            \n",
    "            left = f'ayat1: {sent1} ayat2: {sent2}'\n",
    "            d = {\"src\": left, \"label\": label}\n",
    "            fopen_jsonl.write(f'{json.dumps(d)}\\n')\n",
    "            \n",
    "            left = f'ayat1: {sent1} ayat2: {sent2_ms}'\n",
    "            d = {\"src\": left, \"label\": label}\n",
    "            fopen_jsonl.write(f'{json.dumps(d)}\\n')\n",
    "            \n",
    "            left = f'ayat1: {sent1_ms} ayat2: {sent2_ms}'\n",
    "            d = {\"src\": left, \"label\": label}\n",
    "            fopen_jsonl.write(f'{json.dumps(d)}\\n')\n",
    "            \n",
    "            left = f'ayat1: {sent1_ms} ayat2: {sent2}'\n",
    "            d = {\"src\": left, \"label\": label}\n",
    "            fopen_jsonl.write(f'{json.dumps(d)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shuf test.json > shuffled-test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1000 shuffled-test.json > test-1k.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26768 shuffled-test.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l shuffled-test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"src\": \"ayat1: You have to have good peripheral vision and you have to really concentrate. ayat2: Ia memerlukan tumpuan yang melampau dan kesedaran yang kuat terhadap persekitaran visual anda.\", \"label\": 1}\r\n",
      "{\"src\": \"ayat1: Dole : We ought to agree that somebody else should do it. ayat2: Someone else needs to do it.\", \"label\": 1}\r\n",
      "{\"src\": \"ayat1: Peringkat kedua, tetapi hampir menjanjikan, adalah Morales dari Texas, Scott Harshbarger dari Massachusetts, dan Dennis Vacco dari New York. ayat2: Vacco berasal dari New York.\", \"label\": 1}\r\n",
      "{\"src\": \"ayat1: ya saya terkejut dengan cara mereka merancang tahun lalu mereka tidak benar-benar tidak memilih barisan penyerang besar atau barisan pertahanan yang mereka mahukan jawatan mahir sehingga quarterback mereka benar-benar ayat2: Cara mereka merancang tahun lepas adalah satu kejutan buat saya.\", \"label\": 1}\r\n",
      "{\"src\": \"ayat1: Intifada untuk masa kini ayat2: The extending from the Palestinian uprising until today.\", \"label\": 1}\r\n",
      "{\"src\": \"ayat1: Daerah pelancongan yang luas, ia penuh dengan pusat membeli-belah dan gedung membeli-belah, bersama dengan beberapa restoran yang baik. ayat2: The rich tourist district has shopping centers and a good number of restaurants.\", \"label\": 1}\r\n",
      "{\"src\": \"ayat1: Di luar, yang terletak di taman-taman terawat, adalah sisa-sisa Abbey of Holyrood. ayat2: The gardens containing the remains of the Abbey of Holyrood are in disarray and not well-kept.\", \"label\": 0}\r\n",
      "{\"src\": \"ayat1: yeah it's a U S territory and it's just we own it or ayat2: I used to be great at remembering this type of thing, but now I don't.\", \"label\": 0}\r\n",
      "{\"src\": \"ayat1: Sungguh malang kerana memilih untuk menggunakan McIntyre sebagai gantinya. ayat2: McIntyre dipilih untuk digunakan.\", \"label\": 1}\r\n",
      "{\"src\": \"ayat1: Hall said that Britain has enjoyed a half-century of pre-eminence in this field of endeavor and that this could now be destroyed. ayat2: Selepas setengah abad, Britain ditakdirkan untuk kekal sebagai pemimpin dalam bidang ini.\", \"label\": 0}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 shuffled-test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
